{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "import pandas as pd\n",
    "from dlisio import dlis\n",
    "from tkinter import Tk, filedialog\n",
    "\n",
    "from quick_pp.objects import Well, Project\n",
    "import quick_pp.las_handler as las"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Steps to create \"MOCK\" project\n",
    "1. Run the next cell.\n",
    "2. Specify the example either clastic or carbonate.\n",
    "3. MOCK.qppp project will be saved in notebooks\\data\\04_project folder.\n",
    "\n",
    "* Note that the required curves in the LAS files are 'GR', 'RT', 'NPHI', 'RHOB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = 'carbonate'  # 'clastic'  # \n",
    "folder = 'VOLVE' if example == 'clastic' else 'COSTA'\n",
    "\n",
    "data_path = os.path.join('data', '01_raw', folder)\n",
    "filenames = []\n",
    "for root, dirs, files in os.walk(data_path):\n",
    "    for file in files:\n",
    "        filenames.append(os.path.join(root, file)) if file.endswith('.las') else None\n",
    "\n",
    "project_name = \"MOCK_\" + example\n",
    "project = Project(name=project_name)\n",
    "project.read_las(filenames)\n",
    "project.save()\n",
    "\n",
    "clear_output()               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tkinter import Tk, filedialog\n",
    "\n",
    "# root = Tk()\n",
    "# file_objects = filedialog.askopenfiles(title='Choose well Log ASCII Standard (LAS) files to be combined',\n",
    "#                                         filetype=(('LAS Files', '*.LAS *.las'), ('All Files', '*.*')),\n",
    "#                                         multiple=True,\n",
    "#                                         mode='rb')\n",
    "# root.destroy()\n",
    "# if file_objects:\n",
    "#     project_name = \"MOCK\"    \n",
    "#     project = Project(name=project_name)\n",
    "#     project.read_las([f.name for f in file_objects])\n",
    "#     project.save()\n",
    "\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_parquet(r\"xxx.parquet\")\n",
    "# marker_df = pd.read_csv(r\"zzz.csv\")\n",
    "# marker_df['WELL_NAME'] = marker_df['Well identifier (UWI)']\n",
    "# marker_df['DEPTH'] = marker_df['MDDF(ft)']\n",
    "# marker_df['ZONES'] = marker_df['Surface']\n",
    "\n",
    "# return_df = pd.DataFrame()\n",
    "# for well, data in df.drop('ZONES', axis=1).groupby('WELL_NAME'):\n",
    "#     temp_df = marker_df[marker_df.WELL_NAME == well][['DEPTH', 'ZONES']].copy().sort_values('DEPTH')\n",
    "#     temp_df = pd.merge_asof(\n",
    "#         data, temp_df, on='DEPTH', direction='forward', tolerance=50\n",
    "#     )\n",
    "#     return_df = pd.concat([return_df, temp_df])\n",
    "\n",
    "# project_name = \"BEKK_CLEAN\"    \n",
    "# project = Project(name=project_name)\n",
    "# project.update_data(return_df)\n",
    "# project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading LAS files\n",
    "\n",
    "# root = Tk()\n",
    "# file_objects = filedialog.askopenfiles(title='Choose well Log ASCII Standard (LAS) files to be combined',\n",
    "#                                         filetype=(('LAS Files', '*.LAS *.las'), ('All Files', '*.*')),\n",
    "#                                         multiple=True,\n",
    "#                                         mode='rb')\n",
    "# root.destroy()\n",
    "# input_df, _ = las.read_las_files(file_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading LAS files\n",
    "\n",
    "# root = Tk()\n",
    "# file_objects = filedialog.askopenfiles(title='Choose well Log ASCII Standard (LAS) files to be combined',\n",
    "#                                         filetype=(('LAS Files', '*.LAS *.las'), ('All Files', '*.*')),\n",
    "#                                         multiple=True,\n",
    "#                                         mode='rb')\n",
    "# root.destroy()\n",
    "# output_df, _ = las.read_las_files(file_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_units = dict(\n",
    "    DRHO='g/cc',\n",
    "    DT='us/ft',\n",
    "    DTS='us/ft',\n",
    "    RHOB='g/cc',\n",
    "    NPHI='v/v',\n",
    "    GR='GAPI',\n",
    "    RT='ohm.m',\n",
    "    RM='ohm.m',\n",
    "    RS='ohm.m',\n",
    "    BVW='v/v',\n",
    "    KLOGH='mD',\n",
    "    PHIF='v/v',\n",
    "    SAND='v/v',\n",
    "    VCARB='v/v',\n",
    "    VSH='v/v',\n",
    "    PEF='b/elec',\n",
    "    SW='v/v',\n",
    "    CALI='inches',\n",
    "    BS='inches',\n",
    "    ROP='m/hr'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_folder = r'data\\01_raw\\VOLVE'\n",
    "\n",
    "# merged_df = pd.DataFrame()\n",
    "\n",
    "# for well, data in input_df.groupby('WELL_NAME'):\n",
    "#     temp_output_df = output_df[output_df['WELL_NAME'] == well].sort_values(by='DEPTH')\n",
    "#     temp_df = pd.merge_asof(data.sort_values(by='DEPTH'), temp_output_df, on=['DEPTH'], suffixes=('', '_output'))\n",
    "#     # Get columns with _output suffix\n",
    "#     output_cols = [col for col in temp_df.columns if col.endswith('_output')]\n",
    "    \n",
    "#     # For each _output column, fill null values in original column with values from _output\n",
    "#     for col in output_cols:\n",
    "#         base_col = col.replace('_output', '')\n",
    "#         temp_df[base_col].fillna(temp_df[col], inplace=True)\n",
    "#         # Drop the _output column\n",
    "#         temp_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "#     temp_df.drop(columns=['WELL_NAME', 'UWI'], inplace=True)\n",
    "#     temp_df.dropna(how='all', axis=1, inplace=True)\n",
    "#     las.export_to_las(temp_df, folder=output_folder, well_name=f'{well}', vars_units=vars_units)\n",
    "\n",
    "#     merged_df = pd.concat([merged_df, temp_df])\n",
    "\n",
    "# # merged_df.to_csv('merged_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading DLIS files\n",
    "\n",
    "# root = Tk()\n",
    "# file_objects = filedialog.askopenfiles(title='Choose well Log ASCII Standard (LAS) files to be combined',\n",
    "#                                         filetype=(('LAS Files', '*.DLIS *.dlis'), ('All Files', '*.*')),\n",
    "#                                         multiple=True,\n",
    "#                                         mode='rb')\n",
    "# root.destroy()\n",
    "\n",
    "# dlis_input = pd.DataFrame()\n",
    "# for file_object in file_objects:\n",
    "#     with dlis.load(file_object.name) as (file, *tail):\n",
    "#         well_name = file.origins[0].well_name\n",
    "#         well_name = well_name.replace('/', '-').replace(' ', '-')\n",
    "#         for fr in file.frames:\n",
    "#             temp_df = pd.DataFrame(fr.curves())\n",
    "#             temp_df['WELL_NAME'] = well_name\n",
    "#             temp_df.drop(columns=['FRAMENO'], inplace=True)\n",
    "#             dlis_input = pd.concat([dlis_input, temp_df], ignore_index=True)\n",
    "\n",
    "# # Need to convert depth from 0.1 inch to 0.5 ft and to metres\n",
    "# dlis_input['DEPTH'] = dlis_input.DEPTH / 120 / 3.281"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading DLIS files\n",
    "\n",
    "# root = Tk()\n",
    "# file_objects = filedialog.askopenfiles(title='Choose well Log ASCII Standard (LAS) files to be combined',\n",
    "#                                         filetype=(('LAS Files', '*.DLIS *.dlis'), ('All Files', '*.*')),\n",
    "#                                         multiple=True,\n",
    "#                                         mode='rb')\n",
    "# root.destroy()\n",
    "\n",
    "# dlis_output = pd.DataFrame()\n",
    "# for file_object in file_objects:\n",
    "#     with dlis.load(file_object.name) as (file, *tail):\n",
    "#         well_name = file.origins[0].well_name\n",
    "#         well_name = well_name.replace('/', '-').replace(' ', '-')\n",
    "#         for fr in file.frames:\n",
    "#             temp_df = pd.DataFrame(fr.curves())\n",
    "#             temp_df['WELL_NAME'] = well_name\n",
    "#             temp_df.drop(columns=['FRAMENO'], inplace=True)\n",
    "#             dlis_output = pd.concat([dlis_output, temp_df], ignore_index=True)\n",
    "\n",
    "# # Need to convert depth from 0.1 inch to 0.5 ft \n",
    "# dlis_output['DEPTH'] = dlis_output.DEPTH / 120 / 3.281"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_folder = r'data\\01_raw\\VOLVE'\n",
    "\n",
    "# dlis_merged_df = pd.DataFrame()\n",
    "\n",
    "# for well, data in dlis_input.groupby('WELL_NAME'):\n",
    "#     temp_output_df = dlis_output[dlis_output['WELL_NAME'] == well].sort_values(by='DEPTH')\n",
    "#     temp_df = pd.merge_asof(data.sort_values(by='DEPTH'), temp_output_df, on=['DEPTH'], suffixes=('', '_output'))\n",
    "#     # Get columns with _output suffix\n",
    "#     output_cols = [col for col in temp_df.columns if col.endswith('_output')]\n",
    "    \n",
    "#     # For each _output column, fill null values in original column with values from _output\n",
    "#     for col in output_cols:\n",
    "#         base_col = col.replace('_output', '')\n",
    "#         temp_df[base_col].fillna(temp_df[col], inplace=True)\n",
    "#         # Drop the _output column\n",
    "#         temp_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "#     temp_df.drop(columns=['WELL_NAME', 'UWI'], inplace=True, errors='ignore')\n",
    "#     temp_df.dropna(how='all', axis=1, inplace=True)\n",
    "#     las.export_to_las(temp_df, folder=output_folder, well_name=f'{well.replace(\"/\", \"-\").replace(\" \", \"-\")}', vars_units=vars_units)\n",
    "\n",
    "#     dlis_merged_df = pd.concat([dlis_merged_df, temp_df])\n",
    "\n",
    "# # dlis_merged_df.to_csv('dlis_merged_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
